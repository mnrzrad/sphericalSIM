% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cross_validation.R
\name{cv_two_stage_adaptive}
\alias{cv_two_stage_adaptive}
\title{Two-Stage Cross-Validation with Adaptive Weights}
\usage{
cv_two_stage_adaptive(
  X,
  Y,
  group_idx,
  use_adaptive = TRUE,
  adaptive_method = "grouplasso",
  adaptive_gamma_power = 1,
  initial_lambda_fraction = 0.3,
  nlambda = 12,
  ngamma_coarse = 5,
  ngamma_fine = 8,
  n_folds = 3,
  n_knots = 5,
  lambda_multiplier = 5,
  lambda_min_ratio = 0.1,
  lambda_patience = 3,
  gamma_patience = 2,
  min_groups = 1,
  max_groups = NULL,
  min_valid_folds = 2,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{X}{Design matrix (n × p)}

\item{Y}{Response matrix on unit sphere (n × q)}

\item{group_idx}{List of length G, where each element contains indices of predictors in that group}

\item{use_adaptive}{Use adaptive group lasso weights (default TRUE)}

\item{adaptive_method}{Method for computing adaptive weights: "grouplasso" or "fast" (default "grouplasso")}

\item{adaptive_gamma_power}{Power for adaptive weight computation: w_g = ||β_init_g||^{-γ} (default 1)}

\item{initial_lambda_fraction}{Fraction of lambda_max for initial group lasso fit when computing adaptive weights (default 0.3)}

\item{nlambda}{Number of lambda values in search grid (default 12)}

\item{ngamma_coarse}{Number of gamma values in coarse stage (default 5)}

\item{ngamma_fine}{Number of gamma values in fine stage (default 8)}

\item{n_folds}{Number of cross-validation folds (default 3)}

\item{n_knots}{Number of internal B-spline knots for link function approximation (default 5)}

\item{lambda_multiplier}{Multiplier for lambda_max computation (default 5.0)}

\item{lambda_min_ratio}{Ratio of minimum to maximum lambda (default 0.1)}

\item{lambda_patience}{Number of lambda values without improvement before early stopping (default 3)}

\item{gamma_patience}{Number of gamma values without improvement before early stopping (default 2)}

\item{min_groups}{Minimum number of groups that must be selected (default 1)}

\item{max_groups}{Maximum number of groups allowed. If NULL, uses G (default NULL)}

\item{min_valid_folds}{Minimum number of valid CV folds required (default 2)}

\item{verbose}{Print detailed progress messages (default TRUE)}

\item{...}{Additional arguments passed to \code{\link{spherical_sim_group}}}
}
\value{
List with the following components:
\describe{
  \item{best_lambda}{Optimal lambda from two-stage CV}
  \item{best_gamma}{Optimal gamma from two-stage CV}
  \item{best_cv_error}{Minimum CV error achieved}
  \item{weights}{Vector of group weights (length G) used in final model}
  \item{adaptive_info}{If use_adaptive = TRUE, contains information from adaptive weight computation
        including initial fit and group norms. NULL if use_adaptive = FALSE}
  \item{stage1}{List of CV results from coarse gamma stage. Each element contains output
        from \code{\link{cv_lambda_path_early_stop}}}
  \item{stage2}{List of CV results from fine gamma stage}
}
}
\description{
Performs efficient two-stage cross-validation to jointly select optimal lambda
(group lasso penalty) and gamma (link function smoothness) parameters. Optionally
computes adaptive weights to improve variable selection performance. Features
early stopping at both stages for computational efficiency.
}
\details{
This function implements a sophisticated two-stage cross-validation strategy to
efficiently search the (lambda, gamma) parameter space while optionally using
adaptive weights to improve variable selection.

\strong{Overall Procedure:}
\enumerate{
  \item \strong{Adaptive Weights} (if use_adaptive = TRUE):
    \itemize{
      \item Fit initial model to compute group-wise coefficient norms
      \item Compute weights: w_g = ||β_init_g||^{-γ} * sqrt(|G_g|)
      \item Groups with smaller initial estimates get larger penalties
    }
  \item \strong{Parameter Range Computation}:
    \itemize{
      \item lambda_max: largest lambda that keeps at least one group
      \item gamma_max: computed from data characteristics
      \item Create logarithmic grids for both parameters
    }
  \item \strong{Stage 1 - Coarse Gamma Search}:
    \itemize{
      \item Evaluate ngamma_coarse gamma values on coarse grid
      \item For each gamma, find optimal lambda via CV with early stopping
      \item Track best (lambda, gamma) combination
      \item Stop early if no improvement for gamma_patience iterations
    }
  \item \strong{Stage 2 - Fine Gamma Search}:
    \itemize{
      \item Create fine grid around best gamma from Stage 1 (±3x range)
      \item Re-evaluate with ngamma_fine values
      \item Find optimal (lambda, gamma) on refined grid
      \item Early stopping with gamma_patience
    }
}

\strong{Adaptive Weight Methods:}
\describe{
  \item{grouplasso}{Fits initial group lasso at moderate lambda to get coefficient estimates.
        More accurate but slower. Recommended for most applications.}
  \item{fast}{Uses correlation-based screening to quickly estimate group importance.
        Much faster but potentially less accurate. Good for very large p.}
}

\strong{Early Stopping Strategy:}
Early stopping occurs at two levels:
\itemize{
  \item \emph{Lambda level}: Within each gamma, stop lambda search after lambda_patience
        values without CV improvement (via \code{\link{cv_lambda_path_early_stop}})
  \item \emph{Gamma level}: Stop gamma search after gamma_patience gamma values
        without CV improvement
}

\strong{Computational Efficiency:}
The two-stage approach is much faster than full grid search:
\itemize{
  \item Full grid: O(nlambda × (ngamma_coarse + ngamma_fine)) evaluations
  \item Two-stage with early stopping: Often < 50% of full grid
  \item Lambda sequence evaluated in decreasing order (sparse to dense)
  \item Early stopping saves time on unpromising parameter regions
}

\strong{Choosing Parameters:}
\itemize{
  \item \emph{n_folds}: 3-5 is typical. Larger values give more stable estimates but are slower.
  \item \emph{ngamma_coarse/fine}: 5-8 is usually sufficient. Gamma is often less sensitive than lambda.
  \item \emph{nlambda}: 10-15 provides good coverage. More may be needed for difficult problems.
  \item \emph{patience parameters}: 2-3 works well. Increase if search seems to stop too early.
  \item \emph{adaptive_gamma_power}: 1 is standard. Values > 1 give stronger adaptive effect.
}
}
\examples{
\dontrun{
# Generate data
set.seed(123)
data <- generate_spherical_data(n = 200, p = 40, G = 8,
                                active_groups = c(1, 3, 5),
                                seed = 123)

# Basic adaptive group lasso CV
cv_result <- cv_two_stage_adaptive(
  X = data$X,
  Y = data$Y,
  group_idx = data$group_idx,
  use_adaptive = TRUE,
  adaptive_method = "grouplasso",
  verbose = TRUE
)

# Examine results
cat("Best lambda:", cv_result$best_lambda, "\n")
cat("Best gamma:", cv_result$best_gamma, "\n")
cat("Best CV error:", cv_result$best_cv_error, "\n")

# Fit final model with selected parameters
final_fit <- spherical_sim_group(
  X = data$X,
  Y = data$Y,
  group_idx = data$group_idx,
  lambda = cv_result$best_lambda,
  gamma = cv_result$best_gamma,
  weights = cv_result$weights,
  n_knots = 5,
  verbose = TRUE
)

cat("Selected groups:", final_fit$selected_groups, "\n")
cat("True active groups:", data$active_groups, "\n")

# Compare adaptive vs standard weights
cv_standard <- cv_two_stage_adaptive(
  X = data$X,
  Y = data$Y,
  group_idx = data$group_idx,
  use_adaptive = FALSE,
  verbose = FALSE
)

cat("\nAdaptive CV error:", cv_result$best_cv_error, "\n")
cat("Standard CV error:", cv_standard$best_cv_error, "\n")

# Visualize Stage 1 results
stage1_errors <- sapply(cv_result$stage1, function(x) x$best_error)
stage1_gammas <- sapply(cv_result$stage1, function(x) {
  # Extract gamma from the CV call (stored in parent environment)
  cv_result$stage1[[1]]  # Would need to store gamma explicitly
})

# Alternative: visualize lambda paths for selected gammas
par(mfrow = c(1, 2))

# Stage 1: First gamma
res1 <- cv_result$stage1[[1]]
finite_idx <- is.finite(res1$cv_error)
plot(res1$lambda[finite_idx], res1$cv_error[finite_idx],
     type = "b", log = "x", pch = 19,
     xlab = "Lambda", ylab = "CV Error",
     main = "Stage 1: First Gamma")
abline(v = res1$best_lambda, col = "red", lty = 2)

# Stage 2: Best gamma
best_stage2_idx <- which.min(sapply(cv_result$stage2,
                                    function(x) x$best_error))
res2 <- cv_result$stage2[[best_stage2_idx]]
finite_idx <- is.finite(res2$cv_error)
plot(res2$lambda[finite_idx], res2$cv_error[finite_idx],
     type = "b", log = "x", pch = 19,
     xlab = "Lambda", ylab = "CV Error",
     main = "Stage 2: Best Gamma")
abline(v = res2$best_lambda, col = "red", lty = 2)

# Fast adaptive method for large problems
cv_fast <- cv_two_stage_adaptive(
  X = data$X,
  Y = data$Y,
  group_idx = data$group_idx,
  use_adaptive = TRUE,
  adaptive_method = "fast",  # Much faster
  verbose = TRUE
)

# CV with constraints on model complexity
cv_constrained <- cv_two_stage_adaptive(
  X = data$X,
  Y = data$Y,
  group_idx = data$group_idx,
  min_groups = 2,
  max_groups = 4,  # Force selection of 2-4 groups
  verbose = TRUE
)

# Fine-tuned search with more grid points
cv_fine <- cv_two_stage_adaptive(
  X = data$X,
  Y = data$Y,
  group_idx = data$group_idx,
  nlambda = 20,           # More lambda values
  ngamma_coarse = 8,      # More coarse gamma
  ngamma_fine = 12,       # More fine gamma
  n_folds = 5,            # More folds
  lambda_patience = 4,    # More patient
  gamma_patience = 3,
  verbose = TRUE
)

# Examine adaptive weights
if (!is.null(cv_result$adaptive_info)) {
  cat("\nAdaptive Weights:\n")
  print(data.frame(
    Group = 1:length(cv_result$weights),
    Weight = cv_result$weights,
    InitialNorm = cv_result$adaptive_info$group_norms
  ))

  # Plot weights
  barplot(cv_result$weights, names.arg = 1:length(cv_result$weights),
          xlab = "Group", ylab = "Adaptive Weight",
          main = "Adaptive Weights by Group",
          col = ifelse(1:length(cv_result$weights) \%in\% data$active_groups,
                      "lightblue", "lightgray"))
  legend("topright", c("Active", "Inactive"),
         fill = c("lightblue", "lightgray"))
}

# Time comparison: adaptive methods
system.time({
  cv_grouplasso <- cv_two_stage_adaptive(
    X = data$X, Y = data$Y, group_idx = data$group_idx,
    adaptive_method = "grouplasso", verbose = FALSE
  )
})

system.time({
  cv_fast <- cv_two_stage_adaptive(
    X = data$X, Y = data$Y, group_idx = data$group_idx,
    adaptive_method = "fast", verbose = FALSE
  )
})

# Compare selection performance
fit_grouplasso <- spherical_sim_group(
  data$X, data$Y, data$group_idx,
  cv_grouplasso$best_lambda, cv_grouplasso$best_gamma,
  weights = cv_grouplasso$weights, verbose = FALSE
)

fit_fast <- spherical_sim_group(
  data$X, data$Y, data$group_idx,
  cv_fast$best_lambda, cv_fast$best_gamma,
  weights = cv_fast$weights, verbose = FALSE
)

cat("\nGroup Lasso method selected:", fit_grouplasso$selected_groups, "\n")
cat("Fast method selected:", fit_fast$selected_groups, "\n")
cat("True active groups:", data$active_groups, "\n")
}

}
\references{
- Zou, H. (2006). The adaptive lasso and its oracle properties. Journal of
  the American Statistical Association, 101(476), 1418-1429.
- Yuan, M., & Lin, Y. (2006). Model selection and estimation in regression
  with grouped variables. Journal of the Royal Statistical Society: Series B,
  68(1), 49-67.
- Friedman, J., Hastie, T., & Tibshirani, R. (2010). Regularization paths
  for generalized linear models via coordinate descent. Journal of Statistical
  Software, 33(1), 1-22.
}
\seealso{
\code{\link{cv_lambda_path_early_stop}} for single gamma CV,
\code{\link{compute_adaptive_weights_grouplasso}} for group lasso adaptive weights,
\code{\link{compute_adaptive_weights_fast}} for fast adaptive weights,
\code{\link{spherical_sim_group}} for model fitting,
\code{\link{run_single_simulation}} for using CV in simulations
}
